{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Synthetic Data: Quality\n",
    "\n",
    "We have encountered several methods for generating Synthetic Data.\n",
    "\n",
    "A natural question to ask\n",
    "- How do we know that Synthetic examples are \"good enough\" ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our Generative models were trained so as to minimize a Loss function\n",
    "- Generate a synthetic \"equivalent\" for each training example\n",
    "- We used distance measures to quantify \"equivalent\"\n",
    "    - KL\n",
    "    - JSD\n",
    "    - EMD (Wasserstein)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is creating a synthetic replica for each training example really sufficient (i.e., \"good enough\") ?\n",
    "\n",
    "We discuss metrics that may be used to evaluate the quality of synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is \"good enough\" ?\n",
    "\n",
    "Let us hypothesize that there is some true (but unknown) distribution $\\pdata$ of *real* examples.\n",
    "\n",
    "It should be the goal of our Generative Model to learn to create a distribution $\\pmodel$ of *synthetic* examples\n",
    "such that\n",
    "$$\n",
    "\\pmodel \\approx \\pdata\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is **not** what the Loss function is doing\n",
    "- Two distributions can be identical\n",
    "- Without having samples drawn from each being identical\n",
    "\n",
    "For example: two fair coins, each flipped a large number of times, will not likely produce the same sequence of results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moreover:\n",
    "- Distributions that are \"close\" on an example by example basis\n",
    "- May be sufficiently different as to not be \"good enough\" for some purposes\n",
    "    - Mean value of each feature of a near replica synthetic example off by some constant amount relative to the source training example\n",
    "        - biased estimated of the return of each stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It would seem that \"good enough\" is not a universal measure\n",
    "- May be task specific\n",
    "    - Dependent on how the synthetic data  will be used\n",
    "    \n",
    "It is also likely that, for any given task, there are a number of metrics that are desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quality: Measures\n",
    "\n",
    "We will examine a number of metrics of quality below.\n",
    "\n",
    "The metrics will compare\n",
    "- samples drawn from $\\pmodel$\n",
    "- samples drawn from $\\pdata$\n",
    "\n",
    "in order to address the question\n",
    "$$\n",
    "\\pmodel \\approx \\pdata\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Diversity\n",
    "\n",
    "A *visual* comparison of the distributional properties of the real and synthetic samples.\n",
    "\n",
    "We can compare the distributional properties of the two samples to see if they are \"close enough\".\n",
    "- the moments of each sample's $n$ features\n",
    "- the cross-sectional relationship among the $n$ features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If the examples are higher dimension (e.g., timeseries) we can examine the higher dimensional properties.\n",
    "\n",
    "For example, if an example is a timeseries of daily attributes\n",
    "- we can examine the time relationships\n",
    "\n",
    "We would hope that a high quality synthetic sample demonstrated similar relationships as a real sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If timeseries $\\x = \\x_{(1)}, \\ldots, \\x_{(T)}$ is a sequence of $n$ attributes over $T$ time steps,\n",
    "we can examine\n",
    "- Autocorrelation Function (ACF)\n",
    "    - how do lagged values $\\x_{(\\tt - k)}$ correlate with $\\x_\\tp$, for various lags $k$ ?\n",
    "- Partial Autocorrelation Function (PACF)\n",
    "    - the PACF of lag $k$ is the correlation of $\\x_{(\\tt - k)}$ and $\\x_\\tp$ not explained by lesser lags  $\\x_{(\\tt-k')}$ for $k' \\lt k$\n",
    "- ARCH\n",
    "- GARCH\n",
    "- ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fidelity: Classifier based metrics\n",
    "\n",
    "Can we create a Neural Net Classifier to distinguish between real and synthetic examples ?\n",
    "- Obtain real and  synthetic samples\n",
    "- Split each sample into a train and test cohort.\n",
    "- Train a classifier with a combination of (labeled: Real, Synthetic) examples from the real and synthetic cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After training, we evaluate the Classifier out of sample using a combination of (Real, Synthetic)\n",
    "examples from the test split of both samples.\n",
    "\n",
    "If the out of sample metric is *worse* than the in sample (training)\n",
    "- then the synthetic sample is \"good\"\n",
    "- because a well-trained classifier cannot distinguish real from synthetic examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate (left plot)\n",
    "- a classifier is trained to distinguish between real and synthetic examples (blue `Train` line)\n",
    "    - high accuracy **in-sample**\n",
    "- the classifier's **out of sample** accuracy (orange `Test` line) is much worse\n",
    "- hence: the Classifier **does not distinguish** synthetic from real out of sample\n",
    "\n",
    "<table>\n",
    "    <center><strong>TSTR illustration</strong></center>\n",
    "    <img src=\"images/synth_data_quality_classifier.png\">\n",
    "    <br>\n",
    "    Attribution: https://github.com/stefan-jansen/synthetic-data-for-finance/blob/main/02_evaluating_synthetic_data.ipynb\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier model-based metrics: Inception\n",
    "\n",
    "Rather than train a special purpose Classifier for Real/Synthetic classification,\n",
    "we can *re-purpose* a Classifier for a different task.\n",
    "\n",
    "We illustrate this using a model for Image Classification\n",
    "- because there are many existing, high-quality models for this task\n",
    "    - trained on lots of data\n",
    "    - basis of the ImageNet competition\n",
    "    \n",
    "One can imagine adapting this idea to other types of data for which a high quality classifier is available\n",
    "- This may be more difficult for tasks on which there are no preexisting, high-quality Classifiers\n",
    "- Perhaps because of scarcity of training data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Inception* is a very successful model for Image Classification.\n",
    "- Learns to label Images from a large (1000) fixed number of classes\n",
    "\n",
    "It has been used in several contexts for the purpose of \n",
    "evaluating metrics for synthetic image data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inception Score\n",
    "\n",
    "The idea using a Classifier to compute metrics for synthetic data were proposed in [this paper, Section 4](https://arxiv.org/pdf/1606.03498.pdf).\n",
    "\n",
    "Given a synthetic example $\\hat{\\x}$ the Classifier computes\n",
    "$$\n",
    "\\pr{\\y | \\hat\\x}\n",
    "$$\n",
    "the distribution of labels for the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors propose that\n",
    "- synthetic example $\\hat\\x$ is \"high quality\"\n",
    "- if $\\pr{\\y | \\hat\\x}$ is *low entropy*\n",
    "    - most of the probability is concentrated around a single label\n",
    "    - Classifier is highly confident\n",
    "    \n",
    "That is: a poor quality image would \"confuse\" the Classifier, leaving it uncertain as to the correct label.\n",
    "\n",
    "The authors suggest that high confidence prediction correlates with human judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "They also suggest that the set of synthetic $\\hat\\x$ be *diverse*\n",
    "- not collapse to a single example\n",
    "\n",
    "We can compute the marginal \n",
    "$$\n",
    "\\pr{\\y} = \\int \\pr{\\y | \\hat\\x = G(\\z) } \\, \\partial \\z\n",
    "$$\n",
    "\n",
    "which represents the distribution of class labels over a set of generated examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors suggest that the marginal have *high entropy*\n",
    "- probability spread across many possible labels\n",
    "\n",
    "That is: different choices of random latent $\\z$ give rise to synthetic examples of many different classes.\n",
    "\n",
    "This is a measure of the *diversity* of the synthetic examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "They propose a metric, the *Inception Score (IS)*  based on the  KL divergence for each example\n",
    "- between $\\pr{ \\y | \\hat\\x^\\ip}$ and $\\pr{\\y}$\n",
    "- want this to be high\n",
    "    - highly confident prediction $\\pr{ \\y | \\hat\\x^\\ip}$ for $\\hat\\x$\n",
    "    - compared to $\\pr{\\y}$, the \"average\" (across all examples) prediction\n",
    "\n",
    "$$ \n",
    "\\begin{array} \\\\\n",
    "\\KL^\\ip & = & \\KL( \\pr{ \\y | \\hat\\x^\\ip } \\| \\pr{\\y} ) & \\text{for each synthetic } \\hat\\x^\\ip \\\\\n",
    "\\bar\\KL & = & \\frac{1}{m} \\sum_i \\KL^\\ip & \\text{average over synthetic examples} \\\\\n",
    "\\text{IS} = \\exp( \\bar{\\KL} )\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "It thus combines the high quality and diversity metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "[Here is a tutorial with code](https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/) on calculating the Inception Score.\n",
    "\n",
    "Let's review the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate inception score in numpy\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import exp\n",
    "\n",
    "# calculate the inception score for p(y|x)\n",
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "    # calculate p(y)\n",
    "    p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "    # kl divergence for each image\n",
    "    kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "    # sum over classes\n",
    "    sum_kl_d = kl_d.sum(axis=1)\n",
    "    # average over images\n",
    "    avg_kl_d = mean(sum_kl_d)\n",
    "    # undo the logs\n",
    "    is_score = exp(avg_kl_d)\n",
    "    return is_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given `p_yx`\n",
    "- Python 2D array representing $\\pr{ \\y | \\hat\\x }$\n",
    "- Each row is a different synthetic example $\\hat\\x^\\ip$\n",
    "- Each row is a vector of length $|| C ||$, where $C$ is the set of Classification labels\n",
    "    - `p_yx[i]` is the probability distribution $\\pr{ \\y | \\hat\\x^\\ip }$\n",
    "    \n",
    "The routine `calculate_inception_score(p_yx)` calculates the Inception Score (IS) for the set of synthetic examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is illustrated for low quality examples that classified among 3 labels.\n",
    "- The quality is \"low\" because each $\\pr{ \\y | \\hat\\x^\\ip }$ vector has uniform probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# conditional probabilities for low quality images\n",
    "p_yx = asarray([[0.33, 0.33, 0.33], [0.33, 0.33, 0.33], [0.33, 0.33, 0.33]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Analyzing `calculate_inception_score(p_yx)`\n",
    "- $\\pr{ \\y }$ (the marginal) is computed by averaging across the examples\n",
    "\n",
    "```\n",
    "p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "```\n",
    "- $\\pr{ \\y | \\hat\\x }, \\pr{\\y}$ both represented as vectors of length $|| C ||$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "KL divergence computed (for each row/example)\n",
    "```\n",
    "kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "```\n",
    "- so `kl_d` dimension is $(m, || C ||)$\n",
    "- it is the $|| C ||$ additive terms that are summed to get, $\\KL^\\ip$, the KL divergence for each example\n",
    "\n",
    "```\n",
    "# sum over classes\n",
    "sum_kl_d = kl_d.sum(axis=1)\n",
    "```\n",
    "\n",
    "Thus elements `sum_kl_d` are $m$ scalars representing $\\KL^\\ip$ for each example $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, the Inception Score is\n",
    "- average (over examples $i$) of $\\KL^\\ip$\n",
    "- exponentiated\n",
    "\n",
    "```\n",
    "# average over images\n",
    "avg_kl_d = mean(sum_kl_d)\n",
    "# undo the logs\n",
    "is_score = exp(avg_kl_d)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's see the score for the set of \"low quality\" $\\pr{ \\y | \\hat\\x }$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "p_yx = asarray([[0.33, 0.33, 0.33], [0.33, 0.33, 0.33], [0.33, 0.33, 0.33]])\n",
    "score = calculate_inception_score(p_yx)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And similarly, for high quality (low entropy $\\pr{ \\y | \\hat\\x })$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.999999999999999\n"
     ]
    }
   ],
   "source": [
    "# conditional probabilities for high quality images\n",
    "p_yx = asarray([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "score = calculate_inception_score(p_yx)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Frechet Inception Distance (FID)\n",
    "\n",
    "[This paper, \"Experiments\" section](https://arxiv.org/pdf/1706.08500.pdf)\n",
    "\n",
    "proposes a different use of the Classifier\n",
    "- as a **feature extractor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deep Learning Classifiers have multiple layers, culminating in a Classification Head.\n",
    "\n",
    "Each successive layer is producing an alternate representation of the raw input features\n",
    "- until the layer preceding the Classifier head produces a representation on which the Classification Head can succeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rather than evaluating synthetic examples on properties of their *raw* representation\n",
    "- the authors propose using the representation produced by some layer $L$ of the classifier\n",
    "\n",
    "The belief is that the representation of deeper layers represent increasingly complex *semantic* concepts\n",
    "- rather than the *syntactic* concepts of the raw features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example: consider an image.\n",
    "\n",
    "Rather than considering an image as a collection of pixels (syntax)\n",
    "- Consider its representation in deeper layers that recognize \"concepts\" (semantics): Collections of pixles\n",
    "    - representing complex shapes\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <center><strong>Features by layer</strong></center>\n",
    "    <br>\n",
    "     <!-- edX: Original: <img src=\"images/Layer_features.png\"> replace by EdX created image -->\n",
    "    <img src=\"images/ThreeLayers_W8_L2_Sl21.png\" width=20%>\n",
    "    </div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The vector (of length $n_L$) of layer $L$'s representation can be viewed as a sample from some distribution.\n",
    "\n",
    "We can form the empirical distribution\n",
    "- over real examples\n",
    "- over synthetic examples\n",
    "\n",
    "The idea is that the two empirical distributions should be similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A measure of the dissimilarity of the two distributions is called *Frechet Inception Distance*\n",
    "- uses the Frechet (Wasserstein, EMD) distance between the two distributions\n",
    "- under the assumption that the two distributions are Gaussian\n",
    "    - the Frechet distance is a function of the first two moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[This tutorial](https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/) discusses the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classifier model-based metrics: discussion\n",
    "\n",
    "Elevating the representation to semantics from syntax is not without its issues\n",
    "- The representation of the deepest layers may be too specific to the Classification task\n",
    "- The representation of shallow layers may not convey enough meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- *Adversarial Examples* prove that Classifiers can be fooled with non-meaningful examples\n",
    "    - calling into question whether using a Classifier as a feature extractor captures aspects of being \"real\"\n",
    "    \n",
    "<center>\n",
    "<div>\n",
    "    <center><strong>Adversarial example of \"Speed Limit 45\"</strong></center>\n",
    "    <br>\n",
    "    <img src=\"images/adv_stop_sign.jpg\">\n",
    "    </div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train on Synthetic, Test on Real (TSTR)\n",
    "\n",
    "This metric is relative to a specific Target Task\n",
    "- Given a model for the Target task that is trained using a *synthetic* sample\n",
    "- Compute the test Performance Metric \n",
    "    - *when the test dataset is real*\n",
    "\n",
    "Similarly, train a model on a *real* sample and evaluate it on a test *real* sample (TRTR)\n",
    "\n",
    "The synthetic sample is \"good enough\" for the Target task\n",
    "- if the test Performance Metric (always on a *real* sample)\n",
    "- is comparable for the model trained on synthetic as the model trained on real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate: On an out-of-sample dataset of Real examples (Test Real)\n",
    "- the error of the model trained on Synthetic examples (left)\n",
    "- is lower than the error of the model trained on Real examples (right)\n",
    "\n",
    "\n",
    "<table>\n",
    "    <center><strong>TSTR illustration</strong></center>\n",
    "    <img src=\"images/synth_data_quality_tstr.png\">\n",
    "    <br>\n",
    "    Attribution: https://github.com/stefan-jansen/synthetic-data-for-finance/blob/main/02_evaluating_synthetic_data.ipynb\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other GAN measures\n",
    "\n",
    "[This paper](https://arxiv.org/pdf/1802.03446.pdf) discusses developments of quality metrics for synthetic examples created by GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TimeGAN: Evaluation\n",
    "\n",
    "[Jansen's notebook](https://github.com/stefan-jansen/synthetic-data-for-finance/blob/main/02_evaluating_synthetic_data.ipynb)\n",
    "evaluates the quality of synthetic timeseries created by a TimeGAN,\n",
    "using metrics suggested by the paper's authors.\n",
    "\n",
    "It is worthwhile looking at the results to get a better feel for the evaluation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
